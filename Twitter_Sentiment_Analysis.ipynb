{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66ed122-8eab-4f53-a950-6aef5759c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras import optimizers, layers\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Dropout, Flatten\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71240efd-300f-415d-aad4-6e4a2316c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        \n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aadc1b5-4519-4213-bd47-4dd4a0925e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Get the GloVe into our directory\n",
    "path_to_glove_file = \"glove.6B.100d.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file, encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e49eb88-f472-49cc-993b-50df8eb934bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Datasets/twitter_training.csv', index_col=0, header=None, names=['entity', 'label', 'text'])\n",
    "test = pd.read_csv('Datasets/twitter_validation.csv', index_col=0, header=None, names=['entity', 'label', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3922c159-49fc-47ac-afb8-598c07a108a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase(data):\n",
    "    return data['text'].str.lower()\n",
    "\n",
    "def change_punctuation(data):\n",
    "    return data['text'].str.replace('`', \"'\")\n",
    "\n",
    "def remove_numbers(data):\n",
    "    return data['text'].replace('[^a-zA-z.,!?/:;\\\"\\'\\\\s]', '', regex=True)\n",
    "\n",
    "def remove_special_characters(data):\n",
    "    return data['text'].replace('[^a-zA-Z0-9 ]', '', regex=True)\n",
    "\n",
    "def custom(data):\n",
    "    return data['text'].replace('im', 'i am')\n",
    "\n",
    "def lemmatize(data):\n",
    "    lemmatized_array = []\n",
    "    \n",
    "    for text in data['text']:\n",
    "        lemmatized_text = []\n",
    "        doc = nlp(text)\n",
    "        for token in doc:\n",
    "            lemmatized_text.append(token.lemma_)\n",
    "        lemmatized_array.append(' '.join(lemmatized_text))\n",
    "    return lemmatized_array\n",
    "\n",
    "def stop_words(data):\n",
    "    stop_words_array = []\n",
    "    for text in data['text']:\n",
    "        doc = nlp(text)\n",
    "        filtered_tokens = [token.text for token in doc if not token.is_stop]\n",
    "        stop_words_array.append(' '.join(filtered_tokens))\n",
    "    return stop_words_array\n",
    "\n",
    "def delete_links(data):\n",
    "    return data['text'].replace(r'http\\S+', '', regex=True)\n",
    "\n",
    "def preprocessing(data):\n",
    "    df = data.copy()\n",
    "    df['text'] = lowercase(df)\n",
    "    df['text'] = custom(df)\n",
    "    df['text'] = change_punctuation(df)\n",
    "    df['text'] = lemmatize(df)\n",
    "    df['text'] = remove_numbers(df)\n",
    "    df['text'] = delete_links(df)\n",
    "    df['text'] = remove_special_characters(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f2a1b87-9d8f-4ba6-a7d1-01d0a881fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As seen in dataset, the first entry itself contains many multiple words\n",
    "train.drop_duplicates(subset=['text'], inplace=True)\n",
    "train.reset_index(inplace=True)\n",
    "train['text'] = train['text'].astype('str')\n",
    "test['text'] = test['text'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9286ec13-e13f-47fe-8fdf-a5d1f9ce7827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['text'])\n",
    "len(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "991a6fb6-a999-4f8d-a156-29a000881ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprocessing(train)\n",
    "test = preprocessing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4aae8f6-debb-4ebd-b359-6eb4757b3728",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train['label'] = le.fit_transform(train['label'])\n",
    "test['label'] = le.transform(test['label'])\n",
    "\n",
    "X = train['text']\n",
    "y = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d53240c6-3983-46ec-9a0c-84221932a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "maxlen = 200\n",
    "emb_dim = 50\n",
    "training_samples = int(len(X) * 0.8)\n",
    "\n",
    "text_dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f3ef84e-035e-4b97-b131-ebd6c03aae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "embedding_dim = 128\n",
    "\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "        max_tokens=max_words, # Max number of word in the internal dictionnary. We keep the most frequent\n",
    "        output_mode='int',\n",
    "        output_sequence_length=maxlen  # Size max of text\n",
    "        )\n",
    "\n",
    "vectorize_layer.adapt(text_dataset.batch(64)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06586a38-1bef-4e37-bc6f-55e9032a9474",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorize_layer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "740798cc-c67a-4f47-95f1-353e6540eb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 8305 words (1695 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48c2761f-8bd6-48ed-8969-4337b380085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    trainable=False,\n",
    ")\n",
    "embedding_layer.build((1,))\n",
    "embedding_layer.set_weights([embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0f0e7d5-9a87-4ccc-8498-1d4cddf28e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(1,), dtype=tf.string),\n",
    "    vectorize_layer,\n",
    "    embedding_layer,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation='softmax'),\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa685ba8-8e06-424b-b282-634b2f8b378a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'height' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Flatten\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m----> 5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Flatten(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[43mheight\u001b[49m, width, channels)))  \u001b[38;5;66;03m# Replace height, width, and channels with the correct values\u001b[39;00m\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))  \u001b[38;5;66;03m# Replace num_classes with the correct value\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'height' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(height, width, channels)))  # Replace height, width, and channels with the correct values\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Replace num_classes with the correct value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d54135a-d991-47ac-824c-b4584c7c2cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_1/flatten_1/Reshape defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 639, in run_forever\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1985, in _run_once\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Temp\\ipykernel_1616\\2141241090.py\", line 6, in <module>\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 323, in fit\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 117, in one_step_on_iterator\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 105, in one_step_on_data\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 56, in train_step\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 816, in __call__\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 42, in __call__\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 157, in error_handler\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\sequential.py\", line 203, in call\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 188, in call\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 153, in _run_through_graph\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 572, in call\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 816, in __call__\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 42, in __call__\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 157, in error_handler\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py\", line 54, in call\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 4499, in reshape\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 1378, in reshape\n\nOnly one input size may be -1, not both 0 and 1\n\t [[{{node sequential_1/flatten_1/Reshape}}]] [Op:__inference_one_step_on_iterator_48098]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m cl \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[0;32m      2\u001b[0m                   monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m                   restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      4\u001b[0m                   patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)] \n\u001b[1;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sequential_1/flatten_1/Reshape defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 639, in run_forever\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1985, in _run_once\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Temp\\ipykernel_1616\\2141241090.py\", line 6, in <module>\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 323, in fit\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 117, in one_step_on_iterator\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 105, in one_step_on_data\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 56, in train_step\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 816, in __call__\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 42, in __call__\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 157, in error_handler\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\sequential.py\", line 203, in call\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 188, in call\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 153, in _run_through_graph\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 572, in call\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 816, in __call__\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 42, in __call__\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 157, in error_handler\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py\", line 54, in call\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 4499, in reshape\n\n  File \"C:\\Users\\Chandanmal Bardia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 1378, in reshape\n\nOnly one input size may be -1, not both 0 and 1\n\t [[{{node sequential_1/flatten_1/Reshape}}]] [Op:__inference_one_step_on_iterator_48098]"
     ]
    }
   ],
   "source": [
    "cl = [tf.keras.callbacks.EarlyStopping(\n",
    "                  monitor='val_accuracy',\n",
    "                  restore_best_weights=True,\n",
    "                  patience=10)] \n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=64, callbacks = cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7f237d-e728-4c9b-8e05-dfaa9c0eb12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c37bec-3ee4-401d-ad71-0e0d502e4dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764152b0-b1d3-4399-99a4-d6181233022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "\n",
    "for predictions_array in predictions:\n",
    "    predicted_labels.append(np.argmax(predictions_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d64eb99-1128-4520-b1b5-b24aa5c84fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(predicted_labels, test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd388c3-9ccb-49a1-a7c9-2add6e56a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c9bbc2-c0bf-4098-9c90-e0bf5d670af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c6efd-9402-43c6-bcf0-1e916596e811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44473f36-ce5f-445e-a57e-b7538bb6b395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
